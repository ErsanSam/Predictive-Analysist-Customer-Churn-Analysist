# -*- coding: utf-8 -*-
"""MLT-1_ Ersan Fernando Samjaya

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sSqb60zR1W_x0KA_7URmt6WxXYhuMreC
"""

!pip install pandas-profiling==2.7.1

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from pandas_profiling import ProfileReport
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from collections import Counter
from imblearn.over_sampling import RandomOverSampler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

# load the dataset
dataset = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')
dataset

ProfileReport(dataset)

dataset.info()

# ganti yang kosong dengan np.nan
dataset['TotalCharges'] = dataset['TotalCharges'].replace(' ', np.nan)
dataset['TotalCharges'] = dataset['TotalCharges'].astype('float64')
# konversi ke float64
dataset['SeniorCitizen'] = dataset['SeniorCitizen'].astype('object')
dataset = dataset.drop(dataset.columns[0], axis=1)

dataset.describe()

#menangani missing value
tenure = (dataset.tenure == 0).sum()
print("Nilai 0 di kolom tenure ada: ", tenure)

# cek kolom tenure yg terdapat nilai 0
dataset.loc[(dataset['tenure']==0)]

#mengambil dataset dengan kolom tenure bukan 0
dataset = dataset.loc[(dataset['tenure']!=0)]
dataset.shape

#visualisasikan kolom apakah terdapat outlier
sns.boxplot(x=dataset['tenure'])

#visualisasikan kolom apakah terdapat outlier
sns.boxplot(x=dataset['MonthlyCharges'])

#visualisasikan kolom apakah terdapat outlier
sns.boxplot(x=dataset['TotalCharges'])

# analisis univariat
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'MultipleLines', 'InternetService',
       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',
       'PaymentMethod','Churn']

# mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(dataset, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = dataset.corr().round(2)
# annot = True to print the values inside the square
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

#konversi semua kolom bertipe categorical ke numerik
for column in dataset.columns:
	if dataset[column].dtype == np.number: continue
	# menerapkan label encoding untuk kolom bertipe categorical
	dataset[column] = LabelEncoder().fit_transform(dataset[column])
print(dataset.describe())

dataset.columns

#membagi data menjadi data train dan databtest
X = dataset.drop(["Churn"],axis =1)
y = dataset["Churn"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15102021)

#mengecek isi kolom
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

#mengecek distribusi data 
dataset[numerical_features].hist(bins=50, figsize=(20,15))
plt.show()

#mengecek persentase data churn
print('Jumlah baris dan kolom dari x_train:', X_train.shape,'\nJumlah baris dan kolom dari y_train:', y_train.shape)
print('Prosentase Churn di data Training adalah:')
print(pd.Series(y_train).value_counts(normalize=True))

#menangani imbalance data
over_sampler = RandomOverSampler(random_state=42)
X_res, y_res = over_sampler.fit_resample(X_train, y_train)
print(f"Training target statistics: {Counter(y_res)}")
print(f"Testing target statistics: {Counter(y_test)}")

#cek proporsi isi churn setelah di treatment 
print('Jumlah baris dan kolom dari x_train:', X_res.shape,'\nJumlah baris dan kolom dari y_train:', y_res.shape)
print('Prosentase Churn di data Training adalah:')
print(pd.Series(y_res).value_counts(normalize=True))

#normalisasi data dengan standar scaller
scaler = StandardScaler()
scaler.fit(X_res)
X_res = scaler.transform(X_res) 
X_test = scaler.transform(X_test)
print(X_res)
print(X_test)

#model selection dengan Logistic Regression standard
LR = LogisticRegression()
LR.fit(X_res, y_res)

#model selection dengan Gradient Boosting Classifier standard
gbc = GradientBoostingClassifier()
gbc.fit(X_res, y_res)

#model selection dengan Random Forest Classifier standard
rfc = RandomForestClassifier()
rfc.fit(X_res, y_res)

#Cek akurasi train dan test
mse = pd.DataFrame(columns=['train', 'test'], index=['Gradient Boosting Classifie', 'Logistic Regression', 'Random Forest Classifier'])
model_dict = {'Gradient Boosting Classifie': gbc, 'Logistic Regression': LR, 'Random Forest Classifier': rfc}
  
for name, model in model_dict.items():
    mse.loc[name, 'train'] = model.score(X_res, y_res)*100
    mse.loc[name, 'test'] = model.score(X_test, y_test)*100
 
mse

#visualisasikan akurasi model 
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

#memilih model RFC, kemudian cek precision,recall, f1-score dan support nya
# Predict
y_test_pred = rfc.predict(X_test)
print('Classification Report Testing Model (Random Forest Classifier):')
print(classification_report(y_test, y_test_pred))

#tuning model RFC
rfc_tuned = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=11, max_features='log2',
                       min_impurity_decrease=0.001,
                       min_samples_leaf=4, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=180,
                       verbose=0)
rfc_tuned.fit(X_res,y_res)

# Predict
y_test_pred = rfc_tuned.predict(X_test)
# Print classification report
print('Classification Report Training Model (Gradient Boosting):')
print(classification_report(y_test, y_test_pred))

confusion_matrix_tuned = pd.DataFrame((confusion_matrix(y_test, rfc_tuned.predict(X_test))), ('No churn', 'Churn'), ('No churn', 'Churn'))
confusion_matrix_tuned

# Plot confusion matrix
plt.figure()
heatmap = sns.heatmap(confusion_matrix_tuned, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')
heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)
heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)

plt.title('Confusion Matrix for Training Model\n(Random Forest Classifier)', fontsize=18, color='darkblue')
plt.ylabel('True label', fontsize=14)
plt.xlabel('Predicted label', fontsize=14)
plt.show()